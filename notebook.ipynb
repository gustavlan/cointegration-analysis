{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d331694c",
   "metadata": {},
   "source": [
    "CQF Final project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98420b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from pykalman import KalmanFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc99bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed\n",
      "[*********************100%***********************]  2 of 2 completed\n",
      "[*********************100%***********************]  2 of 2 completed\n",
      "[*********************100%***********************]  2 of 2 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data download...\n",
      "--> Downloading data for: precious_metals_triple\n",
      "--> Downloading data for: oil_pair\n",
      "--> Downloading data for: agri_pair\n",
      "--> Downloading data for: yield_pair\n",
      "--> Downloading data for: currency_pair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  2 of 2 completed\n",
      "[*********************100%***********************]  2 of 2 completed\n",
      "[*********************100%***********************]  2 of 2 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Downloading data for: volatility_pair\n",
      "--> Downloading data for: eu_index_pair_1\n",
      "--> Downloading data for: eu_index_pair_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n",
      "[*********************100%***********************]  2 of 2 completed\n",
      "[*********************100%***********************]  2 of 2 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Downloading data for: fr_banking_pair\n",
      "--> Downloading data for: fast_fashion_pair\n",
      "--> Downloading data for: german_auto_triple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed\n",
      "[*********************100%***********************]  2 of 2 completed\n",
      "[*********************100%***********************]  2 of 2 completed\n",
      "[*********************100%***********************]  2 of 2 completed\n",
      "[                       0%                       ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Downloading data for: investor_ab_pair\n",
      "--> Downloading data for: vw_porsche_pair\n",
      "--> Downloading data for: semiconductor_pair\n",
      "--> Downloading data for: sector_etf_pair\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data download complete.\n",
      "\n",
      "--- Verification ---\n",
      "Successfully downloaded data for 15 groups.\n",
      "The following data groups are now available:\n",
      "- agri_pair\n",
      "- currency_pair\n",
      "- eu_index_pair_1\n",
      "- eu_index_pair_2\n",
      "- fast_fashion_pair\n",
      "- fr_banking_pair\n",
      "- german_auto_triple\n",
      "- investor_ab_pair\n",
      "- oil_pair\n",
      "- precious_metals_triple\n",
      "- sector_etf_pair\n",
      "- semiconductor_pair\n",
      "- volatility_pair\n",
      "- vw_porsche_pair\n",
      "- yield_pair\n",
      "\n",
      "Sample Data for 'volatility_pair':\n",
      "Ticker             VIXY       ^VIX\n",
      "Date                              \n",
      "2020-07-14  2176.800049  29.520000\n",
      "2020-07-15  2119.199951  27.760000\n",
      "2020-07-16  2080.800049  28.000000\n",
      "2020-07-17  2006.400024  25.680000\n",
      "2020-07-20  1913.599976  24.459999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Configuration: Set Dates and Define Asset Tickers ---\n",
    "\n",
    "# Set the time period for data download (last 5 years)\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=5*365)\n",
    "\n",
    "# A dictionary to organize all the asset groups and their tickers\n",
    "# Volatility pair updated to a more robust US Spot vs. Futures ETF pair.\n",
    "asset_groups = {\n",
    "    # Commodities\n",
    "    \"precious_metals_triple\": [\"GC=F\", \"SI=F\", \"PL=F\"], # Gold, Silver, Platinum Futures\n",
    "    \"oil_pair\": [\"CL=F\", \"BZ=F\"],                     # WTI, Brent Crude Futures\n",
    "    \"agri_pair\": [\"ZC=F\", \"ZS=F\"],                    # Corn, Soybean Futures\n",
    "\n",
    "    # Fixed Income & Currency\n",
    "    \"yield_pair\": [\"^TNX\", \"IGLT.L\"],                 # US 10Y Yield, iShares UK Gilts ETF\n",
    "    \"currency_pair\": [\"AUDUSD=X\", \"CADUSD=X\"],        # AUD/USD, CAD/USD\n",
    "\n",
    "    # Volatility\n",
    "    \"volatility_pair\": [\"^VIX\", \"VIXY\"],              # US VIX Index vs. Short-Term VIX Futures ETF*\n",
    "    \n",
    "    # Country Indices\n",
    "    \"eu_index_pair_1\": [\"^FCHI\", \"^GDAXI\"],           # CAC 40, DAX\n",
    "    \"eu_index_pair_2\": [\"^IBEX\", \"FTSEMIB.MI\"],      # IBEX 35, FTSE MIB\n",
    "\n",
    "    # Equities\n",
    "    \"fr_banking_pair\": [\"BNP.PA\", \"GLE.PA\"],          # BNP Paribas, Société Générale\n",
    "    \"fast_fashion_pair\": [\"ITX.MC\", \"HM-B.ST\"],       # Inditex, H&M\n",
    "    \"german_auto_triple\": [\"VOW3.DE\", \"MBG.DE\", \"BMW.DE\"], # VW, Mercedes, BMW\n",
    "    \"investor_ab_pair\": [\"INVE-A.ST\", \"INVE-B.ST\"],    # Investor A, Investor B\n",
    "    \"vw_porsche_pair\": [\"VOW3.DE\", \"P911.DE\"],        # VW, Porsche AG\n",
    "    \"semiconductor_pair\": [\"ASML.AS\", \"IFX.DE\"],      # ASML, Infineon\n",
    "\n",
    "    # ETFs\n",
    "    \"sector_etf_pair\": [\"XLRE\", \"XLU\"]                # Real Estate ETF, Utilities ETF\n",
    "}\n",
    "\n",
    "# --- 2. Data Download ---\n",
    "\n",
    "# Create an empty dictionary to store the downloaded dataframes\n",
    "all_data = {}\n",
    "\n",
    "print(\"Starting data download...\")\n",
    "\n",
    "for group_name, tickers in asset_groups.items():\n",
    "    print(f\"--> Downloading data for: {group_name}\")\n",
    "    try:\n",
    "        # Download daily data for the specified tickers\n",
    "        data = yf.download(tickers,\n",
    "                           start=start_date.strftime('%Y-%m-%d'),\n",
    "                           end=end_date.strftime('%Y-%m-%d'),\n",
    "                           interval=\"1d\",\n",
    "                           auto_adjust=True, # Automatically adjust for splits/dividends\n",
    "                           group_by='ticker')\n",
    "\n",
    "        # When a single ticker in a group fails, yfinance might return a DataFrame\n",
    "        # with only the successful tickers. We need to handle this.\n",
    "        if isinstance(data.columns, pd.MultiIndex):\n",
    "            # If multiple tickers are downloaded, stack them into a clean format\n",
    "            df_processed = data.stack(level=0, future_stack=True).rename_axis(['Date', 'Ticker']).reset_index(level=1)\n",
    "            # We are interested in the 'Close' price\n",
    "            price_data = df_processed.pivot(columns='Ticker', values='Close')\n",
    "        else:\n",
    "            # If only one ticker was successful, it won't have a multi-index\n",
    "            price_data = data[['Close']]\n",
    "            # Rename column to the correct ticker if there's only one\n",
    "            if len(tickers) == 1:\n",
    "                price_data.columns = tickers\n",
    "\n",
    "        # Forward-fill to handle non-trading days and then drop any remaining NaNs\n",
    "        price_data = price_data.ffill().dropna()\n",
    "\n",
    "        if not price_data.empty:\n",
    "            all_data[group_name] = price_data\n",
    "        else:\n",
    "            print(f\"    No data for {group_name} after processing.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    An error occurred while downloading {group_name}: {e}\")\n",
    "\n",
    "print(\"\\nData download complete.\")\n",
    "\n",
    "# --- 3. Verification ---\n",
    "\n",
    "print(\"\\n--- Verification ---\")\n",
    "print(f\"Successfully downloaded data for {len(all_data)} groups.\")\n",
    "print(\"The following data groups are now available:\")\n",
    "for name in sorted(all_data.keys()):\n",
    "    print(f\"- {name}\")\n",
    "\n",
    "# Display the first few rows to verify a successful download\n",
    "print(\"\\nSample Data for 'volatility_pair':\")\n",
    "if 'volatility_pair' in all_data:\n",
    "    print(all_data['volatility_pair'].head())\n",
    "else:\n",
    "    print(\"Could not retrieve 'volatility_pair' data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2400e2bc",
   "metadata": {},
   "source": [
    "\"We need to test if time-series are weakly stationary, or integrated of order zero (I(0)), if its statistical properties—specifically its mean, variance, and autocovariance—are invariant with respect to time. The majority of financial price series do not exhibit this property; they are typically non-stationary and contain a unit root, meaning they are integrated of order one (I(1)). A critical issue arises when standard regression techniques are applied to I(1) series. Regressing one I(1) series on another can lead to a \"spurious regression,\" a situation where high R-squared values and statistically significant coefficients are observed even when no genuine economic relationship exists between the variables. This necessitates formal testing for stationarity.\"\n",
    "\n",
    "The augmented Dickey–Fuller specification is:\n",
    "\n",
    "$$\n",
    "\\Delta y_t = \\alpha + \\beta\\,t + \\gamma\\,y_{t-1}\n",
    "        + \\sum_{i=1}^{p} \\delta_i\\,\\Delta y_{t-i} + \\varepsilon_t\n",
    "$$\n",
    "\n",
    "The hypotheses are:\n",
    "\n",
    "- Null hypothesis: $H_0: \\gamma = 0$\n",
    "  (implying a unit root; the series is non-stationary)\n",
    "\n",
    "- Alternative hypothesis: $H_1: \\gamma < 0$\n",
    "  (implying stationarity)\n",
    "\n",
    "\n",
    "The Kwiatkowski–Phillips–Schmidt–Shin (KPSS) test statistic for trend‐stationarity is given by\n",
    "\n",
    "$$\n",
    "\\mathrm{KPSS} \\;=\\;\n",
    "\\frac{1}{T^2} \\sum_{t=1}^T S_t^2 \\;\\bigg/\\; \\widehat{\\sigma}^2\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$S_t = \\sum_{i=1}^t \\widehat{u}_i$\n",
    "\n",
    "$\\widehat{u}_i = y_i - \\widehat{\\beta}_0 - \\widehat{\\beta}_1\\,i$\n",
    "are the residuals from the OLS regression of \\(y_t\\) on an intercept and time trend.  \n",
    "$(\\widehat{\\sigma}^2\\)$ is a consistent estimate of the long‐run variance of $(\\widehat{u}_t\\)$, often computed via a Newey–West estimator:\n",
    "  $$\n",
    "  \\widehat{\\sigma}^2\n",
    "  = \\frac{1}{T}\\sum_{t=1}^T \\widehat{u}_t^2\n",
    "    \\;+\\; 2 \\sum_{\\ell=1}^L w\\bigl(\\ell,L\\bigr)\\,\n",
    "    \\frac{1}{T}\\sum_{t=\\ell+1}^T \\widehat{u}_t\\,\\widehat{u}_{t-\\ell},\n",
    "  $$\n",
    "  with Bartlett weights \\(w(\\ell,L)=1-\\ell/(L+1)\\).\n",
    "\n",
    "The hypotheses reverse those of the ADF:\n",
    "\n",
    "- **Null hypothesis** (stationarity around a deterministic trend):  \n",
    "  $$H_0:\\; \\{y_t\\}\\text{ is trend‐stationary}$$\n",
    "\n",
    "- **Alternative hypothesis** (presence of a unit root):  \n",
    "  $$H_1:\\; \\{y_t\\}\\text{ has a unit root (non‐stationary)}$$\n",
    "\n",
    "**Interpretation:**  \n",
    "- A large KPSS statistic leads to rejection of \\(H_0\\), suggesting non‐stationarity.  \n",
    "- Used alongside the ADF:  \n",
    "  - **Fail to reject ADF null** (evidence of unit root) **and** **reject KPSS null** (evidence against stationarity) ⇒ strong confirmation that \\(y_t\\) is \\(I(1)\\).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbd2659",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8010f4d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11631f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2020-07-14    40.290001\n",
       "2020-07-15    41.200001\n",
       "2020-07-16    40.750000\n",
       "2020-07-17    40.590000\n",
       "2020-07-20    40.810001\n",
       "                ...    \n",
       "2025-07-07    67.930000\n",
       "2025-07-08    68.330002\n",
       "2025-07-09    68.379997\n",
       "2025-07-10    66.570000\n",
       "2025-07-11    68.449997\n",
       "Name: CL=F, Length: 1258, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['oil_pair']['CL=F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6d4b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ADF Test for WTI Crude Oil Prices ---\n",
      "Test Statistic: -2.1941\n",
      "P-value: 0.2084\n",
      "Critical Values:\n",
      "\t1%: -3.4356\n",
      "\t5%: -2.8639\n",
      "\t10%: -2.5680\n",
      "Conclusion: Weak evidence against null hypothesis, fail to reject H0.\n",
      "Data has a unit root and is likely non-stationary.\n"
     ]
    }
   ],
   "source": [
    "def adf_test(series, name=''):\n",
    "    \"\"\"\n",
    "    Performs the Augmented Dickey-Fuller test on a time series.\n",
    "    \"\"\"\n",
    "    print(f'--- ADF Test for {name} ---')\n",
    "    # The adfuller function returns a tuple of results\n",
    "    result = adfuller(series.dropna()) # dropna() to be safe\n",
    "    \n",
    "    print(f'Test Statistic: {result[0]:.4f}')\n",
    "    print(f'P-value: {result[1]:.4f}')\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'\\t{key}: {value:.4f}')\n",
    "\n",
    "    if result[1] <= 0.05:\n",
    "        print(\"Conclusion: Strong evidence against the null hypothesis (H0), reject H0.\")\n",
    "        print(\"Data has no unit root and is likely stationary.\")\n",
    "    else:\n",
    "        print(\"Conclusion: Weak evidence against null hypothesis, fail to reject H0.\")\n",
    "        print(\"Data has a unit root and is likely non-stationary.\")\n",
    "\n",
    "# Test one of the crude oil price series\n",
    "wti_prices = all_data['oil_pair']['CL=F']\n",
    "adf_test(wti_prices, name='WTI Crude Oil Prices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33c58a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- KPSS Test for WTI Crude Oil Prices ---\n",
      "Test Statistic: 1.2333\n",
      "P-value: 0.0100\n",
      "Critical Values:\n",
      "\t10%: 0.3470\n",
      "\t5%: 0.4630\n",
      "\t2.5%: 0.5740\n",
      "\t1%: 0.7390\n",
      "Conclusion: Strong evidence against the null hypothesis (H0), reject H0.\n",
      "Data is likely non-stationary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_102523/3425884912.py:7: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is smaller than the p-value returned.\n",
      "\n",
      "  result = kpss(series.dropna(), regression='c') # 'c' for constant trend\n"
     ]
    }
   ],
   "source": [
    "def kpss_test(series, name=''):\n",
    "    \"\"\"\n",
    "    Performs the KPSS test for stationarity.\n",
    "    \"\"\"\n",
    "    print(f'\\n--- KPSS Test for {name} ---')\n",
    "    # The kpss function returns a tuple of results\n",
    "    result = kpss(series.dropna(), regression='c') # 'c' for constant trend\n",
    "    \n",
    "    print(f'Test Statistic: {result[0]:.4f}')\n",
    "    print(f'P-value: {result[1]:.4f}')\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[3].items():\n",
    "        print(f'\\t{key}: {value:.4f}')\n",
    "\n",
    "    if result[1] < 0.05:\n",
    "        print(\"Conclusion: Strong evidence against the null hypothesis (H0), reject H0.\")\n",
    "        print(\"Data is likely non-stationary.\")\n",
    "    else:\n",
    "        print(\"Conclusion: Weak evidence against null hypothesis, fail to reject H0.\")\n",
    "        print(\"Data is likely stationary.\")\n",
    "\n",
    "# --- Example Usage ---\n",
    "kpss_test(wti_prices, name='WTI Crude Oil Prices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9916a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Engle-Granger Test for CL=F and BZ=F ---\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'CL=F'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDateParseError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/cqf_final_exam/venv/lib/python3.12/site-packages/pandas/core/indexes/datetimes.py:603\u001b[39m, in \u001b[36mDatetimeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    602\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m603\u001b[39m     parsed, reso = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_with_reso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, pytz.NonExistentTimeError) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/cqf_final_exam/venv/lib/python3.12/site-packages/pandas/core/indexes/datetimes.py:559\u001b[39m, in \u001b[36mDatetimeIndex._parse_with_reso\u001b[39m\u001b[34m(self, label)\u001b[39m\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_parse_with_reso\u001b[39m(\u001b[38;5;28mself\u001b[39m, label: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m     parsed, reso = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_parse_with_reso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    561\u001b[39m     parsed = Timestamp(parsed)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/cqf_final_exam/venv/lib/python3.12/site-packages/pandas/core/indexes/datetimelike.py:293\u001b[39m, in \u001b[36mDatetimeIndexOpsMixin._parse_with_reso\u001b[39m\u001b[34m(self, label)\u001b[39m\n\u001b[32m    291\u001b[39m     label = \u001b[38;5;28mstr\u001b[39m(label)\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m parsed, reso_str = \u001b[43mparsing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_datetime_string_with_reso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqstr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m reso = Resolution.from_attrname(reso_str)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/parsing.pyx:442\u001b[39m, in \u001b[36mpandas._libs.tslibs.parsing.parse_datetime_string_with_reso\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/parsing.pyx:666\u001b[39m, in \u001b[36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mDateParseError\u001b[39m: Unknown datetime string format, unable to parse: CL=F",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     30\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# --- Example Usage ---\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Let's test the oil pair for cointegration\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m oil_spread = \u001b[43mengle_granger_coint_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwti_prices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCL=F\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBZ=F\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m oil_spread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     37\u001b[39m     oil_spread.plot(title=\u001b[33m'\u001b[39m\u001b[33mWTI-Brent Spread (Engle-Granger)\u001b[39m\u001b[33m'\u001b[39m, figsize=(\u001b[32m12\u001b[39m, \u001b[32m6\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mengle_granger_coint_test\u001b[39m\u001b[34m(df, y_col, x_col)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mPerforms the Engle-Granger two-step cointegration test.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03mReturns the spread series if cointegrated, otherwise returns None.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Engle-Granger Test for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m y = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_col\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      8\u001b[39m x = df[x_col]\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Step 1: Run the regression (OLS)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/cqf_final_exam/venv/lib/python3.12/site-packages/pandas/core/series.py:1130\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1127\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1129\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1133\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/cqf_final_exam/venv/lib/python3.12/site-packages/pandas/core/series.py:1246\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1243\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1245\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1246\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/cqf_final_exam/venv/lib/python3.12/site-packages/pandas/core/indexes/datetimes.py:605\u001b[39m, in \u001b[36mDatetimeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    603\u001b[39m     parsed, reso = \u001b[38;5;28mself\u001b[39m._parse_with_reso(key)\n\u001b[32m    604\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, pytz.NonExistentTimeError) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m605\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    606\u001b[39m \u001b[38;5;28mself\u001b[39m._disallow_mismatched_indexing(parsed)\n\u001b[32m    608\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._can_partial_date_slice(reso):\n",
      "\u001b[31mKeyError\u001b[39m: 'CL=F'"
     ]
    }
   ],
   "source": [
    "def engle_granger_coint_test(df, y_col, x_col):\n",
    "    \"\"\"\n",
    "    Performs the Engle-Granger two-step cointegration test.\n",
    "    Returns the spread series if cointegrated, otherwise returns None.\n",
    "    \"\"\"\n",
    "    print(f'\\n--- Engle-Granger Test for {y_col} and {x_col} ---')\n",
    "    y = df[y_col]\n",
    "    x = df[x_col]\n",
    "    \n",
    "    # Step 1: Run the regression (OLS)\n",
    "    x_const = sm.add_constant(x) # Add a constant for the intercept\n",
    "    model = sm.OLS(y, x_const).fit()\n",
    "    hedge_ratio = model.params[x_col]\n",
    "    print(f'Hedge Ratio (beta): {hedge_ratio:.4f}')\n",
    "    \n",
    "    # Step 2: Calculate the spread (residuals)\n",
    "    spread = y - hedge_ratio * x\n",
    "    \n",
    "    # Step 3: Perform ADF test on the spread\n",
    "    adf_results = adfuller(spread.dropna())\n",
    "    p_value = adf_results[1]\n",
    "    \n",
    "    print(f'Spread ADF Test P-value: {p_value:.4f}')\n",
    "    \n",
    "    if p_value <= 0.05:\n",
    "        print(\"Conclusion: The spread is stationary. The pair is likely cointegrated. ✅\")\n",
    "        return spread\n",
    "    else:\n",
    "        print(\"Conclusion: The spread is not stationary. The pair is not cointegrated. ❌\")\n",
    "        return None\n",
    "\n",
    "# --- Example Usage ---\n",
    "# Let's test the oil pair for cointegration\n",
    "#oil_spread = engle_granger_coint_test(wti_prices, y_col='CL=F', x_col='BZ=F')\n",
    "\n",
    "\n",
    "if oil_spread is not None:\n",
    "    oil_spread.plot(title='WTI-Brent Spread (Engle-Granger)', figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11629ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
